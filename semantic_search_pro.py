import os
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from sentence_transformers import SentenceTransformer
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

# --- –ù–ê–°–¢–†–û–ô–ö–ò ---
COLLECTION_NAME = "kaspi_report"
MODEL_NAME = "all-MiniLM-L6-v2"
# –ò—â–µ–º —Ñ–∞–π–ª —Ä—è–¥–æ–º —Å–æ —Å–∫—Ä–∏–ø—Ç–æ–º. –ï—Å–ª–∏ —É –≤–∞—Å –æ–Ω –≤ –ø–∞–ø–∫–µ data, –ø–æ–º–µ–Ω—è–π—Ç–µ –Ω–∞ "data/docs/..."
PDF_PATH = "data/docs/sample.pdf"

class VectorSearchEngine:
    def __init__(self):
        print("‚è≥ –ó–∞–≥—Ä—É–∂–∞—é –Ω–µ–π—Ä–æ—Å–µ—Ç—å (–µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç–µ –ø–µ—Ä–≤—ã–π —Ä–∞–∑, —ç—Ç–æ –∑–∞–π–º–µ—Ç –º–∏–Ω—É—Ç—É)...")
        self.model = SentenceTransformer(MODEL_NAME)
        self.vector_size = 384
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –±–∞–∑—É –≤ –ø–∞–º—è—Ç–∏
        self.client = QdrantClient(":memory:")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∫–æ–ª–ª–µ–∫—Ü–∏—è, –µ—Å–ª–∏ –Ω–µ—Ç ‚Äî —Å–æ–∑–¥–∞–µ–º
        if not self.client.collection_exists(COLLECTION_NAME):
            self.client.create_collection(
                collection_name=COLLECTION_NAME,
                vectors_config=VectorParams(size=self.vector_size, distance=Distance.COSINE),
            )

    def process_pdf(self, file_path: str):
        print(f"üìÑ –ü—Ä–æ–±—É—é –æ—Ç–∫—Ä—ã—Ç—å —Ñ–∞–π–ª: {file_path}")
        
        if not os.path.exists(file_path):
            print(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω! –°–æ–∑–¥–∞—é —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, —á—Ç–æ–±—ã –ø–æ–∫–∞–∑–∞—Ç—å, –∫–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç...")
            # –°–æ–∑–¥–∞–µ–º —Ñ–µ–π–∫–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ PDF –Ω–µ—Ç
            texts = [
                "Kaspi.kz showed strong results in 3Q 2025 with 20% revenue growth.",
                "Hepsiburada acquisition in T√ºrkiye helps international expansion.",
                "Net income increased by 12% year-over-year.",
                "The supply of smartphones remains subject to temporary disruption in Kazakhstan."
            ]
            chunks = [{"text": t, "page": 1} for t in texts]
        else:
            # –ï—Å–ª–∏ —Ñ–∞–π–ª –µ—Å—Ç—å ‚Äî —á–∏—Ç–∞–µ–º –µ–≥–æ
            loader = PyPDFLoader(file_path)
            docs = loader.load()
            splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
            split_docs = splitter.split_documents(docs)
            chunks = [{"text": d.page_content, "page": d.metadata.get("page", 0)+1} for d in split_docs]
            print(f"üß© –î–æ–∫—É–º–µ–Ω—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤.")

        # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è
        print("üöÄ –ü—Ä–µ–≤—Ä–∞—â–∞—é —Ç–µ–∫—Å—Ç –≤ –≤–µ–∫—Ç–æ—Ä—ã...")
        points = []
        for i, item in enumerate(chunks):
            text = item["text"]
            vector = self.model.encode(text).tolist()
            
            points.append(PointStruct(
                id=i,
                vector=vector,
                payload={"text": text, "page": item["page"]}
            ))
            
        self.client.upsert(collection_name=COLLECTION_NAME, points=points)
        print(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –í –±–∞–∑–µ {len(points)} –≤–µ–∫—Ç–æ—Ä–æ–≤.")

    def search(self, query: str):
        if not query: return
        print(f"\nüîé –ò—â—É: '{query}'")
        query_vector = self.model.encode(query).tolist()
        
        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ò—Å–ø–æ–ª—å–∑—É–µ–º query_points –≤–º–µ—Å—Ç–æ search
        hits = self.client.query_points(
            collection_name=COLLECTION_NAME,
            query=query_vector,
            limit=3,
            with_payload=True
        ).points
        
        print("=" * 50)
        for hit in hits:
            print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {hit.score:.3f} | –°—Ç—Ä. {hit.payload['page']}")
            print(f"üìÑ ...{hit.payload['text'][:200].replace(chr(10), ' ')}...")
            print("-" * 50)

if __name__ == "__main__":
    app = VectorSearchEngine()
    app.process_pdf(PDF_PATH)
    
    print("\nüí° –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã (–Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º –∏–ª–∏ —Ä—É—Å—Å–∫–æ–º).")
    while True:
        q = input("\n–í–∞—à –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'q' –¥–ª—è –≤—ã—Ö–æ–¥–∞): ")
        if q.lower() in ['q', 'exit']: break
        app.search(q)