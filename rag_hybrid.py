import os
from dotenv import load_dotenv
from supabase import create_client, Client
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∏
load_dotenv()
supabase: Client = create_client(os.environ.get("SUPABASE_URL"), os.environ.get("SUPABASE_KEY"))
openai_client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
model = SentenceTransformer("all-MiniLM-L6-v2")

# --- –ü–û–ò–°–ö–û–í–´–ï –§–£–ù–ö–¶–ò–ò ---
def search_vectors(query):
    vector = model.encode(query).tolist()
    response = supabase.rpc("match_documents", {
        "query_embedding": vector,
        "match_threshold": 0.3, # –ü–æ—Ä–æ–≥ —á—É—Ç—å –Ω–∏–∂–µ, —á—Ç–æ–±—ã –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        "match_count": 10       # –ë–µ—Ä–µ–º 10 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    }).execute()
    return response.data if response.data else []

def search_keywords(query):
    response = supabase.rpc("kw_match_documents", {
        "query_text": query,
        "match_count": 10       # –ë–µ—Ä–µ–º 10 –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤
    }).execute()
    return response.data if response.data else []

def rrf_fusion(semantic_results, keyword_results, k=60):
    fused_scores = {}
    doc_content = {} 

    # –°–ª–∏–≤–∞–µ–º –¥–≤–∞ —Å–ø–∏—Å–∫–∞
    for doc_list in [semantic_results, keyword_results]:
        for rank, doc in enumerate(doc_list):
            doc_id = doc['id']
            doc_content[doc_id] = doc 
            if doc_id not in fused_scores: fused_scores[doc_id] = 0
            fused_scores[doc_id] += 1 / (rank + k)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º
    sorted_ids = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)
    
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ø-5 –ª—É—á—à–∏—Ö
    final_results = []
    for doc_id, score in sorted_ids[:5]:
        final_results.append(doc_content[doc_id])
    
    return final_results

# --- –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø RAG ---
def ask_hybrid_bot(question):
    print(f"\nüë§ –í–æ–ø—Ä–æ—Å: {question}")
    print("SEARCHING... –ó–∞–ø—É—Å–∫–∞—é –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫...")
    
    # 1. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫
    vec_res = search_vectors(question)
    kw_res = search_keywords(question)
    
    # 2. RRF –°–ª–∏—è–Ω–∏–µ
    top_docs = rrf_fusion(vec_res, kw_res)
    
    if not top_docs:
        print("‚ùå –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        return

    # 3. –°–æ–±–∏—Ä–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context_text = ""
    for doc in top_docs:
        context_text += doc['content'] + "\n---\n"
        
    print("üß† THINKING... –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç...")

    # 4. –ó–∞–ø—Ä–æ—Å –∫ GPT
    response = openai_client.chat.completions.create(
        messages=[
            {"role": "system", "content": "–¢—ã —é—Ä–∏—Å—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ —Ç–æ—á–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç."},
            {"role": "user", "content": f"–ö–æ–Ω—Ç–µ–∫—Å—Ç:\n{context_text}\n\n–í–æ–ø—Ä–æ—Å: {question}"}
        ],
        model="gpt-3.5-turbo",
    )
    
    print("\n" + "="*50)
    print(f"ü§ñ –û–¢–í–ï–¢:\n{response.choices[0].message.content}")
    print("="*50)

if __name__ == "__main__":
    while True:
        q = input("\n–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å (–∏–ª–∏ 'exit'): ")
        if q.lower() == 'exit': break
        ask_hybrid_bot(q)